from __future__ import print_function
# Djangoplicity
# Copyright 2007-2008 ESA/Hubble
#
# Authors:
#   Lars Holm Nielsen <lnielsen@eso.org>
#   Luis Clara Gomes <lcgomes@eso.org>

from builtins import filter
from builtins import str
from builtins import object
import os
import shutil
import inspect
from datetime import datetime, timedelta

from celery.task.control import revoke
from django.conf import settings
from django.contrib.contenttypes.models import ContentType
from django.contrib.postgres.fields import JSONField
from django.core.cache import cache
from django.core.exceptions import ImproperlyConfigured, ObjectDoesNotExist
from django.db import connection, models
from django.db.models.base import ModelBase
from django.db.models.fields import CharField
from django.core.exceptions import FieldDoesNotExist
from django.db.models.signals import post_save, pre_save, post_delete
from django.dispatch import Signal
from functools import partial
from django.utils.timezone import is_naive, make_aware
from django.utils.translation import ugettext_lazy as _

from djangoplicity.archives import _gen_cache_key, CACHE_PREFIX
from djangoplicity.archives.contrib.security import StaticFilesProtectorCache
from djangoplicity.archives.contrib.social.tasks import facebook_refresh
from djangoplicity.archives.fields import ReleaseDateTimeField
from djangoplicity.archives.resources import ResourceManager
from djangoplicity.archives.tasks import clear_archive_list_cache, \
    embargo_release_date_task
from future.utils import with_metaclass


__all__ = ( 'ArchiveModel', 'post_rename' )


post_rename = Signal(providing_args=['old_pk', 'new_pk'])


def add_model_field( attrs, cls, name, *args, **kwargs ):
    if name in attrs:
        raise ImproperlyConfigured( _( 'Cannot add model field to Model from Archive - field name %s already exists' % name ) )
    attrs[name] = cls( **kwargs )


def add_model_value( metaclass, value, name ):
    if name in metaclass.__dict__:
        raise ImproperlyConfigured( _( 'Cannot add attribute to Model from Archive - attribute name %s already exists' % name ) )
    setattr(metaclass, name, value)


def add_field( metaclass, attrs, name, default_value, fieldclass, **field_kwargs ):
    try:
        value = getattr( metaclass, name )
    except AttributeError:
        value = default_value
        add_model_value( metaclass, value, name )

    if value:
        try:
            field_name = getattr( metaclass, '%s_fieldname' % name )
        except AttributeError:
            field_name = name
            add_model_value( metaclass, field_name, '%s_fieldname' % name )
        add_model_field( attrs, fieldclass, field_name, **field_kwargs )


def release_date_handler( sender, instance, **kwargs ):
    """
    Handles release date automatic setting of now()
    when it is published and doesn't have a release date set
    """
    if instance.published and not instance.release_date:
        instance.release_date = datetime.now()


def resource_deletion_handler(sender, instance, **kwargs):
    """
    Handles automatic resource deletion, and called when an Archive object is deleted.
    Hooked on post_delete signals
    If Archive.delete_instead_of_copy is set and True then the archives are
    deleted, otherwise they are moved to a Trash folder
    """
    if not issubclass(sender, ArchiveModel):
        return

    if not settings.ARCHIVE_AUTO_RESOURCE_DELETION:
        return

    if settings.USE_I18N and hasattr(sender, 'Translation') and instance.is_translation():
        # Removing a translation doesn't remove the resources.
        return

    TRASH_DIR = os.path.join(settings.MEDIA_ROOT, 'Trash')

    tmp_dir = os.path.join(TRASH_DIR, datetime.now().isoformat() + '-deleted')

    errors = []

    delete = getattr(instance.Archive.Meta, 'delete_instead_of_copy', False)

    for attr in dir(instance.Archive):
        try:
            rm = getattr(instance.Archive, attr, None)
        except AttributeError:
            pass

        if not isinstance(rm, ResourceManager):
            continue

        r = getattr(instance, '%s%s' % (instance.Archive.Meta.resource_fields_prefix, attr), False)
        if not r:
            continue

        try:
            if delete:
                # Delete the files instead of moving them to Trash
                if os.path.isdir(r.path):
                    shutil.rmtree(r.path)
                else:
                    os.remove(r.path)
            else:
                new_path = os.path.join(tmp_dir, r.name)
                new_dir, _new_file = os.path.split(new_path)

                os.makedirs(new_dir)
                # move
                shutil.move(r.path, new_path)
        except OSError:
            errors.append( attr )

        # do nothing about errors at the moment.


def cache_handler( sender, created=False, **kwargs ):
    """
    Cache handler for post_save signals and rename method. Invalidates any detail cache pages
    generated by the archive_detail view.
    """

    if 'raw' in kwargs and kwargs['raw']:
        return

    if issubclass( sender, ArchiveModel ) and not created:
        instance = kwargs['instance']

        # Check if idfield exists
        try:
            sender._meta.get_field( sender.Archive.Meta.idfield )
        except ( FieldDoesNotExist, AttributeError ):
            sender._meta.get_field( 'id' )

        try:
            if settings.USE_I18N and hasattr( sender, 'Translation' ):
                # Important to query for instance.source_id and not instance.source. When deleting a source, then all translations are
                # delete as well. This method will be called once per deleted source/translation AFTER the objects have been deleted.
                # Hence, unless the translation have already fetched the instance.source, then it will fail with instance.source but not
                # instance.source_id.
                object_id = getattr( instance, sender.Archive.Meta.idfield ) if instance.is_source() else getattr( instance, 'source_id' )

                if sender.__name__.endswith('Proxy'):
                    # instance is a translation
                    key = _gen_cache_key( CACHE_PREFIX['detail_view'], sender.__name__.replace('Proxy', ''), object_id, lang=instance.lang )
                    cache.delete( key )
                else:
                    keys = []
                    for lang, _title in settings.LANGUAGES:
                        keys.append( _gen_cache_key( CACHE_PREFIX['detail_view'], sender.__name__.replace('Proxy', ''), object_id, lang=lang ) )
                    cache.delete_many( keys )
            else:
                kwargs = { 'lang': settings.LANGUAGE_CODE } if settings.USE_I18N else {}
                key = _gen_cache_key( CACHE_PREFIX['detail_view'], sender.__name__, getattr( instance, sender.Archive.Meta.idfield ), **kwargs )
                cache.delete( key )
        except AttributeError:
            return


def static_files_protection_handler( sender, instance, **kwargs ):
    """
    Post save signal handler that ensures that all the resources are protected
    under embargo, staging and unpublished areas.
    """
    if 'raw' in kwargs and kwargs['raw']:
        return

    # Only run on production:
    if settings.DEBUG:
        return

    if issubclass( sender, ArchiveModel ):
        StaticFilesProtectorCache.run_async()


def clear_views_cache_handler( sender, instance, **kwargs ):
    """
    Post save signal to clear views cache related to the current model
    """
    if 'raw' in kwargs and kwargs['raw']:
        return

    keylist_key = '%s_keys' % sender.get_cache_key_prefix()
    cache_keys = cache.get(keylist_key)
    if cache_keys:
        cache.delete_many(cache_keys)
        cache.delete(keylist_key)


class ArchiveBase( ModelBase ):
    """
    class SomeModel( Archive, models.Model ):
        id = models.SlugField()
        ... fields ...

        class Archive(object):
            resource = ResourceManager(...)

            class Meta:
                root = 'archives/books/' # Required
                idfield = 'id'         # Required. Defaults to 'id'.
                resource_fields_prefix = # Defaults to 'resource_'
                datefield = ...       # Defaults to fields.ReleaseDateTimeField
                datefield_kwargs = ...   # Defaults to {}
                release_date = True   # Defaults to false
                release_date_fieldname = # Defaults to 'release_date'
                embargo_date = True   # Defaults to false
                embargo_date_fieldname = # Defaults to 'embargo_date'
                last_modified = True     # Defaults to false
                last_modified_fieldname  # Defaults to 'last_modified'
                created = True         # Defaults to false
                created_fieldname       # Defaults to 'created'
                published = True         # Defaults to false
                published_fieldname =   # Defaults to 'published'
                release_date_owner = False # Defaults to false
                release_date_owner_fieldname = # Defaults to 'release_date_owner'
                ignore_upsale_warnings = True  # Set to ignore upscale warnings
                                               # for given model
                delete_instead_of_copy = False  # If set to true the archives will
                                                # be deleted instead of being
                                                # moved to Trash
    """
    def __new__( cls, name, bases, attrs ):
        """
        """
        super_new = super( ArchiveBase, cls ).__new__

        try:
            parents = [b for b in bases if issubclass( b, ArchiveModel )]
            if not parents:
                return super_new( cls, name, bases, attrs )
        except NameError:
            # 'Archive' isn't defined yet, meaning we're looking at Djangoplicity's own
            # Model class, defined below.
            return super_new( cls, name, bases, attrs )

        # Exclude proxy models
        if 'Meta' in attrs and hasattr( attrs['Meta'], 'proxy' ) and attrs['Meta'].proxy is True:
            return super_new( cls, name, bases, attrs )

        # Exclude "fake" migrations
        if attrs['__module__'] == '__fake__':
            return super_new( cls, name, bases, attrs )

        # Archive base class
        base_cls = parents[0]

        #
        # Get Archive and Archive.Meta class from attributes
        #
        try:
            archiveclass = attrs['Archive']
            metaclass = getattr( archiveclass, 'Meta' )
        except KeyError:
            raise ImproperlyConfigured( _( 'Missing Archive class in Model.' ) )
        except AttributeError:
            raise ImproperlyConfigured( _( 'Meta class missing in Archive class.' ) )

        # Setup id field (by default this is id.
        idfield = getattr( metaclass, 'idfield', 'id' )
        metaclass.idfield = idfield

        if idfield not in attrs:
            # since we started using class inheritance in ArchiveModels,we bypassed
            # the archive id field because it could be defined in another subclass.
            if len( bases ) == 1:
                raise ImproperlyConfigured( _( 'Archive ID field (%s) is missing from Model.' % idfield ) )

        #
        # Setup date-based archives - add field
        #
        fieldclass = getattr( metaclass, 'datefield', ReleaseDateTimeField )
        field_kwargs = getattr( metaclass, 'datefield_kwargs', {} )

        release_date_defaults = getattr( metaclass, 'release_date', False )
        add_field( metaclass, attrs, 'release_date', release_date_defaults, fieldclass, **field_kwargs )
        add_field( metaclass, attrs, 'embargo_date', release_date_defaults, fieldclass, **field_kwargs )
        add_field( metaclass, attrs, 'published', False, models.BooleanField, **{ 'default': False, 'db_index': True, 'verbose_name': _( "Published" ) } )
        add_field( metaclass, attrs, 'last_modified', False, models.DateTimeField, **{ 'auto_now': True, 'verbose_name': _( "Last modified" ) } )
        add_field( metaclass, attrs, 'created', False, models.DateTimeField, **{ 'auto_now_add': True, 'verbose_name': _( "Created" ) } )
        add_field( metaclass, attrs, 'release_date_owner', False, models.SlugField, **{ 'db_index': True, 'blank': True, 'null': True } )

        # Add fields to store Celery task ID for release and embargo
        add_field(metaclass, attrs, 'release_task_id', release_date_defaults, CharField, **{'max_length': 64, 'blank': True, 'null': True})
        add_field(metaclass, attrs, 'embargo_task_id', release_date_defaults, CharField, **{'max_length': 64, 'blank': True, 'null': True})

        # Add field to store resources checksums
        add_field(metaclass, attrs, 'checksums', dict, JSONField, **{'blank': True, 'null': True})

        #
        # Resource short-cuts
        #
        try:
            prefix = getattr( metaclass, 'resource_fields_prefix' )
        except AttributeError:
            prefix = 'resource_'
            add_model_value( metaclass, prefix, 'resource_fields_prefix' )

        # Note if using archiveclass.__dict__ you won't get inherited fields.
        # Compared to dir( archiveclass )
        archiveattrs = [x for x in dir(archiveclass) if not x.startswith('_')]

        resources = {}
        for attrname in archiveattrs:
            manager = getattr( archiveclass, attrname )

            if isinstance( manager, ResourceManager ):
                field_name = '%s%s' % ( prefix, attrname )
                resources[attrname] = manager

                if field_name in attrs:
                    raise ImproperlyConfigured( _( 'Cannot add model field to Model from Archive - field name %s already exists' % field_name ) )

                # Adds a property to the Model class.
                # The property is partial specified method _get_resource( resource_name=... )
                # Hence, accessing obj.resource_original will be a call to obj._get_resource( resource_name='original' )
                # It returns a File object, so it can be used more or less as if it
                # was a database FileField.
                attrs[field_name] = property( partial( base_cls._get_resource, resource_name=attrname ) )

        #
        # Create class
        #
        newclass = super_new( cls, name, bases, attrs )

        #
        # Ingest manager's attribute name into manager, since this determines
        # - This is done for convenience, when accessing a manager, and so that you
        #   don't need to give the name twice.
        #
        for ( attrname, manager ) in resources.items():
            manager.name = attrname

        #
        # Connect signal handlers
        #
        post_save.connect( cache_handler, sender=newclass )

        post_save.connect( static_files_protection_handler, sender=newclass )

        post_save.connect( clear_views_cache_handler, sender=newclass )

        post_delete.connect( resource_deletion_handler, sender=newclass )

        post_delete.connect( cache_handler, sender=newclass )

        if getattr( metaclass, 'release_date', False ) and getattr( metaclass, 'published', False ):
            pre_save.connect( release_date_handler, sender=newclass )

        return newclass


class ArchiveModel( with_metaclass(ArchiveBase, object) ):
    """
    Super class for all Models that needs archive functionality.

    WARNING: When specifying this class in the list of super class
    this class **MUST** be the first one!

    The following will work as expected::

        class SomeModel( ArchiveModel, models.Model ):
            ...

    The following will *NOT* work as expected::

        class SomeModel( models.Model, ArchiveModel ):
            ...

    The reason is that it is the first super class' metaclass which
    is used to create the SomeModel class. Most of the magic that
    ArchiveModel adds to SomeModel is done by the ArchiveModel's
    metaclass (ArchiveBase), and hence nothing of the magic will be
    added unless ArchiveModel is specified as the first super class.
    """

    def save(self, *args, **kwargs ):
        if not self._state.adding and not self.pk:
            raise ValueError('Empty PK is not allowed')

        super(ArchiveModel, self).save(*args, **kwargs)

    def rename( self, new_pk ):
        """
        Method to rename and archive item.

        Example::
            class SomeArchive:
                ...

                class Meta:
                    rename_pk = ('tablename','pk_name')
                    rename_fks = (('related_tablename','fk_name'),...)
        """
        try:
            self.__class__.objects.get( pk=new_pk )
            raise Exception( "Object with new primary key does already exists." )
        except ObjectDoesNotExist:
            pass

        # Get keys to rename.
        pk = self.Archive.Meta.rename_pk
        if hasattr( self.Archive.Meta, 'rename_fks' ):
            fks = self.Archive.Meta.rename_fks
        else:
            fks = []

        cache_handler( self.__class__, created=False, instance=self )

        #
        # Rename keys
        #
        cursor = connection.cursor()

        # Get list of related resources and rename them, this has to be done
        # before we update the keys in the DB
        def get_related(x):
            return x.startswith('related_') or x in ('image', 'video', 'comparison')

        for related_resource in filter(get_related, dir(self)):
            related_resource = getattr(self, related_resource)

            if not related_resource:
                continue

            #  Check if the attribute is an ArchiveModel (like for POTW)
            #  or a ManytoMany (PR, Ann, etc.)
            if isinstance(related_resource, ArchiveModel):
                related_resources = [related_resource]
            else:
                related_resources = related_resource.all()

            for resource in related_resources:
                if not resource.pk.startswith(self.pk):
                    print('** Not renaming %s for %s' % (resource.pk, self.pk))
                    continue

                # Generate destination pk:
                destpk = resource.pk.replace(self.pk, new_pk, 1)

                # Make sure that the destination pk doesn't already exist:
                try:
                    resource.__class__.objects.get( pk=destpk )
                    raise Exception( "Object (%s) with new primary key (%s) does already exists." %
                            (resource.__class__.__name__, destpk))
                except ObjectDoesNotExist:
                    pass
                resource.rename(destpk)

        # Get list of translations (if any) and rename them
        if settings.USE_I18N and hasattr(self, 'Translation') and self.is_source():
            for _lang, translation in self.get_translations(filter_kwargs={})['translations'].items():
                if not translation.pk.startswith(self.pk):
                    continue

                # Generate destination pk:
                destpk = translation.pk.replace(self.pk, new_pk, 1)

                # Make sure that the destination pk doesn't already exist:
                try:
                    translation.__class__.objects.get( pk=destpk )
                    raise Exception( "Translation for object (%s) with new primary key (%s) does already exists." %
                            (translation.__class__.__name__, destpk))
                except ObjectDoesNotExist:
                    pass

                # We want to rename the "Proxy" version of the model, otherwise
                # 'return self.__class__.objects.get( pk=new_pk )' won't work
                # We use the inspect module to find which module hosts the
                # Archive item, and then look for a Proxy model (e.g.: we look
                # for ImageProxy in the same module as Image)

                module = inspect.getmodule(translation)
                proxymodel_name = '%sProxy' % translation.__class__.__name__

                if not hasattr(module, proxymodel_name):
                    continue
                proxymodel = getattr(module, proxymodel_name)

                # Rename translation (get should always be successful as we know
                # there is a translation for this language, as reported by
                # get_translations():
                proxytranslation = proxymodel.objects.get(pk=translation.pk)
                proxytranslation.rename(destpk)
                print('** Renaming %s Translation %s to %s' % (proxytranslation.__class__.__name__, translation.pk, destpk))

        # Update key in primary table
        sql = """UPDATE "%(table)s" SET "%(key)s"='%(new_key)s' WHERE "%(key)s"='%(old_key)s'"""
        if connection.vendor == 'mysql':
            sql = "UPDATE `%(table)s` SET `%(key)s`='%(new_key)s' WHERE `%(key)s`='%(old_key)s'"

        cursor.execute( sql % { 'key': pk[1], 'table': pk[0], 'new_key': new_pk, 'old_key': self.pk } )

        for fk in fks:
            # We only update the table if it actually exists
            if fk[0] not in connection.introspection.table_names():
                continue

            sql = """UPDATE "%(table)s" SET "%(key)s"='%(new_key)s' WHERE "%(key)s"='%(old_key)s'"""
            if connection.vendor == 'mysql':
                sql = "UPDATE `%(table)s` SET `%(key)s`='%(new_key)s' WHERE `%(key)s`='%(old_key)s'"
            cursor.execute( sql % { 'key': fk[1], 'table': fk[0], 'new_key': new_pk, 'old_key': self.pk } )

        # Rename the admin log history, as multiple objects can have the
        # same ID we also filter with the content_id
        content_type = ContentType.objects.get_for_model(self)
        sql = """UPDATE "django_admin_log" SET "object_id"='{new_pk}' WHERE "object_id"='{old_pk}' AND "content_type_id"={content_type_id}"""
        if connection.vendor == 'mysql':
            sql = "UPDATE `django_admin_log` SET `object_id`='{new_pk}' WHERE `object_id`='{old_pk}' AND `content_type_id`={content_type_id}"
        cursor.execute(sql.format(new_pk=new_pk, old_pk=self.pk, content_type_id=content_type.pk))

        #
        # Rename resources
        #

        # Only delete resources for source objects
        resource_names = [
            name for name, type_ in list(vars(self.Archive).items())
            if isinstance(type_, ResourceManager)
        ]

        for rname in resource_names:
            self._rename_resource( rname, new_pk )

        new_instance = self.__class__.objects.get( pk=new_pk )

        # Revoke existing embargo/release tasks and create new one
        # accordingly
        new_instance.set_embargo_date_task()
        new_instance.set_release_date_task()
        new_instance.save()

        # Send signals
        post_rename.send(sender=self.__class__, old_pk=self.pk, new_pk=new_pk)
        return new_instance

    def delete_resources( self ):
        """
        Delete all resources for an archive item.
        """
        #
        # Rename resources
        #
        resource_names = [
            name for name, type_ in list(vars(self.Archive).items())
            if isinstance(type_, ResourceManager)
        ]

        failed = []
        for rname in resource_names:
            try:
                self._delete_resource( rname )
            except IOError:
                failed.append( rname )

        if failed:
            raise Exception( "Failed to delete %s resource(s)" % failed )

        return True

    def move_resources( self, new_pk ):
        """ Move all resources """
        try:
            self.__class__.objects.get( pk=new_pk )
        except ObjectDoesNotExist:
            raise Exception( "Object you are trying to move resources to does not exists." )

        #
        # Rename resources
        #
        resource_names = [
            name for name, type_ in list(vars(self.Archive).items())
            if isinstance(type_, ResourceManager)
        ]

        for rname in resource_names:
            self._rename_resource( rname, new_pk )

        return True

    def locked_resources( self ):
        """
        Return a list of resources that should not be touched.
        """
        return []

    def clear_cache( self ):
        """
        Clear the views cache for the current Archive
        """
        cache_handler( self.__class__, created=False, instance=self )

    def embargo_date_action(self):
        '''
        Called at the time defined by embargo_date
        '''
        # Clear the cache
        clear_archive_list_cache()

    def release_date_action(self):
        '''
        Called at the time defined by release_date
        '''
        # Clear the cache
        clear_archive_list_cache()

        from django.contrib.sites.models import Site
        domain = Site.objects.get_current().domain
        url = '%s%s' % (domain, self.get_absolute_url())
        facebook_refresh.delay(url)

    def set_embargo_date_task(self):
        '''
        Configure the task to run embargo_date_action
        '''
        if not hasattr(self, 'embargo_task_id'):
            # Model has embargo_date set to Flase
            return

        # We don't want to schedule tasks too far in the future as they would end
        # up clogging rabbitmq, we set the limit to 4 weeks
        one_month = datetime.now() + timedelta(weeks=4)

        # Revoke the previous task if any
        if self.embargo_task_id:  # pylint: disable=E0203
            revoke(self.embargo_task_id)  # pylint: disable=E0203

        if self.embargo_date and self.embargo_date < one_month:
            eta = self.embargo_date
            if is_naive(eta):
                eta = make_aware(eta)

            task = embargo_release_date_task.apply_async(
                eta=eta,
                args=[self._meta.app_label, self._meta.model_name,
                      self.pk, 'embargo'],
            )
            self.embargo_task_id = task.task_id

    def set_release_date_task(self):
        '''
        Configure the task to run release_date_action
        '''
        if not hasattr(self, 'release_task_id'):
            # Model has release_date set to Flase
            return

        # We don't want to schedule tasks too far in the future as they would end
        # up clogging rabbitmq, we set the limit to 4 weeks
        one_month = datetime.now() + timedelta(weeks=4)

        # Revoke the previous task if any
        if self.release_task_id:  # pylint: disable=E0203
            revoke(self.release_task_id)  # pylint: disable=E0203

        if self.release_date and self.release_date < one_month:
            task = embargo_release_date_task.apply_async(
                eta=self.release_date,
                args=[self._meta.app_label, self._meta.model_name,
                      self.pk, 'release'],
            )
            self.release_task_id = task.task_id

    def _delete_resource( self, resource_name ):
        if settings.USE_I18N and hasattr( self, 'Translation' ) and self.is_translation():
            # Ignore for translations
            return

        resource = getattr( self, "resource_%s" % resource_name )

        if resource:
            shutil.rmtree( resource.path )

    def _rename_resource( self, resource_name, new_pk ):
        if settings.USE_I18N and hasattr( self, 'Translation' ) and self.is_translation():
            # Ignore for translations
            return

        resource = getattr( self, "resource_%s" % resource_name )

        if resource:
            dirname = os.path.dirname( resource.path )
            oldname = os.path.basename( resource.path )
            _base, ext = os.path.splitext( oldname )
            newname = "%s%s" % ( new_pk, ext )
            newpath = os.path.join( dirname, newname )
            os.rename( resource.path, newpath )

    def _get_resource( self, resource_name ):
        """
        Get resource (a subclass of File) for the specified resource_name.

        Result is cached for future accesses to the same resource.
        """

        if not hasattr( self, '_resource_cache' ):
            self._resource_cache = {}

        if resource_name not in self._resource_cache:
            manager = getattr( self.Archive, resource_name )
            self._resource_cache[resource_name] = manager.get_resource_for_instance( self )

        return self._resource_cache[resource_name]

    def clear_resource_cache(self):
        '''
        Under some circumstances we might want to clear the resource cache:
        For example djangoplicity-cutter has a loop that waits for the original
        format to be accessible through NFS, the cache needs to be cleared
        at each iteration to prevent it from always retuning None if the file
        wasn't there in the first iteration
        '''
        self._resource_cache = {}

    def get_object_identifier( self ):
        """
        Return a unique identifier for this object
        """
        return self.get_object_identifier_for_pk( self.pk )

    @classmethod
    def get_cache_key_prefix( cls ):
        """
        Returns a key prefix to be used for caching purposes
        """
        return cls.__name__

    @classmethod
    def cache_set( cls, key, data ):
        """
        Caches 'data' with key 'key', stores the key so that it can be
        cleared. We store the key twice: once so that the archive specific
        cache can be cleared (e.g.: all Image cache), once for all the
        archives
        """
        keylist_key = '%s_keys' % cls.get_cache_key_prefix()
        ca = cache.get(keylist_key)

        # Add key to list of keys for model if necessary
        if ca:
            if key not in ca:
                ca.append(key)
        else:
            ca = [key]

        cache.set(keylist_key, ca, 99999999)

        # Also store key in global key list
        global_keylist_key = 'global_cache_keys'
        ca = cache.get(global_keylist_key)

        # Add key to list of keys for model if necessary
        if ca:
            if key not in ca:
                ca.append(key)
        else:
            ca = [key]

        cache.set(global_keylist_key, ca, 99999999)

        cache.set(key, data, 60 * 5)

    @classmethod
    def cache_get( cls, key ):
        """
        Returns data with key 'key' from cache (or None)
        """
        return cache.get(key)

    @classmethod
    def get_object_identifier_for_pk( cls, pk='' ):
        """
        Return a unique identifier for this object
        """
        return str( pk )
        #return "%s.%s:%s" % ( self._meta.app_label, self._meta.model_name, str( self.pk ) )
